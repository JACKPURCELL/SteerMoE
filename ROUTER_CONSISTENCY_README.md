# Router Consistency Loss - ä½¿ç”¨è¯´æ˜

## æ¦‚è¿°

Router Consistency Loss æ˜¯ä¸€ä¸ªå¯é€‰çš„è®­ç»ƒä¼˜åŒ–ï¼Œç”¨äºå¼ºåˆ¶ batch å†…çš„ safe å’Œ unsafe æ ·æœ¬ä½¿ç”¨ä¸€è‡´çš„ router åˆ†å¸ƒã€‚è¿™æ˜¯ä¸€ä¸ªæ¶ˆèå®éªŒåŠŸèƒ½ï¼Œå¯ä»¥å•ç‹¬å¯ç”¨æˆ–ä¸ unsafe experts finetuning ç»“åˆä½¿ç”¨ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ ¸å¿ƒæ€æƒ³
- **é—®é¢˜**: åŸæ–¹æ³•åª finetune unsafe expertsï¼Œå¯èƒ½å½±å“æ¨¡å‹æ•´ä½“è¡Œä¸º
- **è§£å†³**: æ·»åŠ  router consistency lossï¼Œè®© safe/unsafe æ ·æœ¬æ¿€æ´»ç›¸åŒçš„ä¸“å®¶
- **ä¼˜åŠ¿**: ç†è®ºä¸Šå¯ä¿æŒ safe ä»»åŠ¡æ€§èƒ½ï¼ŒåŒæ—¶æå‡ unsafe æ‹’ç»èƒ½åŠ›

### ä¸‰ä¸ªå…³é”®å‚æ•°
1. `--no_finetune_unsafe_experts`: ç¦ç”¨ expert finetuningï¼ˆåªè®­ç»ƒ routerï¼‰
2. `--use_router_consistency_loss`: å¯ç”¨ router consistency loss
3. `--router_consistency_weight`: æ§åˆ¶ loss æƒé‡ï¼ˆé»˜è®¤ 0.1ï¼‰

### æœ€ç®€å•çš„ç”¨æ³•

```bash
# åŸæœ‰æ–¹æ³•ï¼ˆåª finetune expertsï¼‰
python train_batch_unsafe_experts.py --mode selective

# æ–°æ–¹æ³•1: åªä¼˜åŒ– router
python train_batch_unsafe_experts.py --mode selective \
    --no_finetune_unsafe_experts --use_router_consistency_loss

# æ–°æ–¹æ³•2: ä¸¤è€…ç»“åˆï¼ˆæ¨èï¼‰
python train_batch_unsafe_experts.py --mode selective \
    --use_router_consistency_loss
```

## è®¾è®¡åŸç†

### æŸå¤±è®¡ç®—ä½ç½®
åœ¨ **router logits** ä¸Šè®¡ç®— KL æ•£åº¦ï¼ˆæ¨èæ–¹æ¡ˆï¼‰ï¼š
- âœ… å®Œå…¨å¯å¾®ï¼Œæ¢¯åº¦å¯ä»¥æµå‘ router
- âœ… ç†è®ºåˆç†ï¼šKL æ•£åº¦å¤©ç„¶åº¦é‡æ¦‚ç‡åˆ†å¸ƒå·®å¼‚
- âœ… å…¨å±€ä¸€è‡´æ€§ï¼šçº¦æŸæ‰€æœ‰ä¸“å®¶çš„é€‰æ‹©æ¦‚ç‡

### KL æ•£åº¦å½¢å¼
å¯¹æ¯ä¸€å±‚ lï¼Œè®¡ç®—ï¼š
```python
safe_avg_probs = softmax(safe_router_logits[l]).mean(dim=0)    # [n_experts]
unsafe_avg_probs = softmax(unsafe_router_logits[l]).mean(dim=0) # [n_experts]

# å¯¹ç§° KL æ•£åº¦ï¼ˆé»˜è®¤ï¼‰
kl_loss = (KL(safe || unsafe) + KL(unsafe || safe)) / 2
```

ä½¿ç”¨å¹³å‡åˆ†å¸ƒçš„åŸå› ï¼š
- Batch å†… safe å’Œ unsafe æ•°é‡å¯èƒ½ä¸åŒï¼Œé¿å…ä¸€å¯¹ä¸€é…å¯¹å¤æ‚æ€§
- å¹³å‡åˆ†å¸ƒæ›´ç¨³å®šï¼Œä»£è¡¨è¯¥ batch ä¸­æ ·æœ¬çš„"å…¸å‹" router è¡Œä¸º

### KL æ•£åº¦ç±»å‹
1. **Forward KL**: `KL(safe || unsafe)` - è®© unsafe æ¥è¿‘ safe
2. **Reverse KL**: `KL(unsafe || safe)` - è®© safe æ¥è¿‘ unsafe
3. **Symmetric**: `(KL(safe || unsafe) + KL(unsafe || safe)) / 2` - åŒå‘çº¦æŸï¼ˆ**æ¨è**ï¼‰

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

**1. ä»…ä½¿ç”¨ Router Consistency Lossï¼ˆæ¶ˆèå®éªŒ - Router Onlyï¼‰**
```bash
python train_batch_unsafe_experts.py \
    --model_name allenai/OLMoE-1B-7B-0125-Instruct \
    --mode selective \
    --no_finetune_unsafe_experts \
    --use_router_consistency_loss \
    --router_consistency_weight 0.1 \
    --router_consistency_type symmetric \
    --router_consistency_layers all \
    --output_dir ./output_router_only
```
**è¯´æ˜**: åªè®­ç»ƒ router å‚æ•°ï¼Œexperts ä¿æŒå†»ç»“

**2. ä»… Finetune Unsafe Expertsï¼ˆæ¶ˆèå®éªŒ - Expert Onlyï¼‰**
```bash
python train_batch_unsafe_experts.py \
    --model_name allenai/OLMoE-1B-7B-0125-Instruct \
    --mode selective \
    --output_dir ./output_expert_only
```
**è¯´æ˜**: è¿™æ˜¯åŸæœ‰çš„æ–¹æ³•ï¼Œåª finetune unsafe expertsï¼Œä¸ä½¿ç”¨ router consistency loss

**3. Router Consistency + Unsafe Experts Finetuningï¼ˆç»„åˆä¼˜åŒ–ï¼‰**
```bash
python train_batch_unsafe_experts.py \
    --model_name allenai/OLMoE-1B-7B-0125-Instruct \
    --mode selective \
    --use_router_consistency_loss \
    --router_consistency_weight 0.1 \
    --output_dir ./output_combined
```
**è¯´æ˜**: åŒæ—¶è®­ç»ƒ unsafe experts å’Œ routerï¼Œä¸¤ä¸ªä¼˜åŒ–ç›®æ ‡ç»“åˆ

**4. Baselineï¼ˆå†»ç»“æ¨¡å‹ï¼‰**
```bash
python train_batch_unsafe_experts.py \
    --model_name allenai/OLMoE-1B-7B-0125-Instruct \
    --mode selective \
    --no_finetune_unsafe_experts \
    --output_dir ./output_frozen_baseline
```
**è¯´æ˜**: æ‰€æœ‰å‚æ•°å†»ç»“ï¼Œä½œä¸ºå¯¹ç…§ï¼ˆå‡ ä¹æ²¡æœ‰å®é™…æ„ä¹‰ï¼‰

### è¶…å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--finetune_unsafe_experts` | flag | True | æ˜¯å¦ finetune unsafe expert MLPsï¼ˆé»˜è®¤å¯ç”¨ï¼‰ |
| `--no_finetune_unsafe_experts` | flag | - | ç¦ç”¨ unsafe expert finetuningï¼ˆç”¨äº router-only æ¶ˆèï¼‰ |
| `--use_router_consistency_loss` | flag | False | æ˜¯å¦å¯ç”¨ router ä¸€è‡´æ€§æŸå¤± |
| `--router_consistency_weight` | float | 0.1 | Router ä¸€è‡´æ€§æŸå¤±çš„æƒé‡ |
| `--router_consistency_type` | str | symmetric | KL æ•£åº¦ç±»å‹ï¼šforward/reverse/symmetric |
| `--router_consistency_layers` | str | all | è®¡ç®—å“ªäº›å±‚ï¼šall æˆ– unsafe_only |

**é‡è¦è¯´æ˜**:
- é»˜è®¤æƒ…å†µä¸‹ `finetune_unsafe_experts=True`ï¼Œä¿æŒåŸæœ‰è¡Œä¸º
- ä½¿ç”¨ `--no_finetune_unsafe_experts` æ¥ç¦ç”¨ expert finetuning
- å¦‚æœåªç”¨ router consistency lossï¼ˆ`--no_finetune_unsafe_experts --use_router_consistency_loss`ï¼‰ï¼Œåªæœ‰ router å‚æ•°ä¼šè¢«è®­ç»ƒ

### è¶…å‚æ•°è°ƒä¼˜å»ºè®®

1. **`router_consistency_weight`**
   - å»ºè®®èŒƒå›´ï¼š0.01 ~ 1.0
   - èµ·å§‹å€¼ï¼š0.1
   - å¦‚æœ router loss å¤ªå¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œé™ä½æ­¤å€¼
   - å¦‚æœæƒ³è¦æ›´å¼ºçš„ router ä¸€è‡´æ€§çº¦æŸï¼Œå¢å¤§æ­¤å€¼

2. **`router_consistency_type`**
   - æ¨èï¼š`symmetric`ï¼ˆåŒå‘çº¦æŸï¼Œæœ€ç¨³å®šï¼‰
   - å¦‚æœæƒ³æ˜ç¡®è®© unsafe å­¦ä¹  safe çš„ router è¡Œä¸ºï¼š`forward`
   - å¦‚æœæƒ³è®© safe ä¹Ÿé€‚åº” unsafeï¼š`reverse`ï¼ˆä¸å¤ªæ¨èï¼‰

3. **`router_consistency_layers`**
   - æ¨èï¼š`all`ï¼ˆå…¨é¢çº¦æŸï¼‰
   - å¦‚æœè®¡ç®—èµ„æºæœ‰é™æˆ–æƒ³å‡å°‘çº¦æŸï¼š`unsafe_only`ï¼ˆç›®å‰æœªå®ç°ï¼Œéœ€è¦ä¼ å…¥ unsafe experts ä¿¡æ¯ï¼‰

## å®éªŒè®¾è®¡å»ºè®®

### æ¶ˆèå®éªŒçŸ©é˜µ

| å®éªŒ | Finetune Experts | Router Consistency | å¯è®­ç»ƒå‚æ•° | ç›®çš„ |
|------|-----------------|-------------------|-----------|------|
| Baseline | âŒ | âŒ | æ—  | å†»ç»“æ¨¡å‹å¯¹ç…§ï¼ˆå¯é€‰ï¼‰ |
| Expert Only | âœ… | âŒ | Unsafe Experts | ä»… finetune experts çš„æ•ˆæœ |
| Router Only | âŒ | âœ… | Routers | ä»… router ä¸€è‡´æ€§çš„æ•ˆæœ |
| Combined | âœ… | âœ… | Experts + Routers | ä¸¤è€…ç»“åˆçš„ååŒæ•ˆåº” |

### å®Œæ•´è¿è¡Œç¤ºä¾‹

```bash
MODEL_NAME="allenai/OLMoE-1B-7B-0125-Instruct"

# Ablation 1: ä»… Finetune Unsafe Expertsï¼ˆåŸæœ‰æ–¹æ³•ï¼Œæ¨èä½œä¸º baselineï¼‰
python train_batch_unsafe_experts.py \
    --model_name $MODEL_NAME \
    --mode selective \
    --output_dir ./exp_expert_only \
    --num_epochs 3 \
    --batch_size 16

# Ablation 2: ä»… Router Consistency Loss
python train_batch_unsafe_experts.py \
    --model_name $MODEL_NAME \
    --mode selective \
    --no_finetune_unsafe_experts \
    --use_router_consistency_loss \
    --router_consistency_weight 0.1 \
    --output_dir ./exp_router_only \
    --num_epochs 3 \
    --batch_size 16

# Ablation 3: ä¸¤è€…ç»“åˆï¼ˆæ¨èï¼‰
python train_batch_unsafe_experts.py \
    --model_name $MODEL_NAME \
    --mode selective \
    --use_router_consistency_loss \
    --router_consistency_weight 0.1 \
    --output_dir ./exp_combined \
    --num_epochs 3 \
    --batch_size 16

# ä¸åŒæƒé‡çš„æ•æ„Ÿæ€§åˆ†æ
for weight in 0.01 0.05 0.1 0.5 1.0; do
    python train_batch_unsafe_experts.py \
        --model_name $MODEL_NAME \
        --mode selective \
        --use_router_consistency_loss \
        --router_consistency_weight $weight \
        --output_dir ./exp_weight_$weight \
        --num_epochs 3 \
        --batch_size 16
done

# ä¸åŒ KL ç±»å‹çš„å¯¹æ¯”
for kl_type in forward reverse symmetric; do
    python train_batch_unsafe_experts.py \
        --model_name $MODEL_NAME \
        --mode selective \
        --no_finetune_unsafe_experts \
        --use_router_consistency_loss \
        --router_consistency_type $kl_type \
        --output_dir ./exp_kl_$kl_type \
        --num_epochs 3 \
        --batch_size 16
done
```

## å®ç°ç»†èŠ‚

### æ¶æ„æ”¯æŒ
- âœ… OLMoE: `model.layers[i].mlp.gate`
- âœ… Mixtral: `model.layers[i].mlp.block_sparse_moe.gate`
- å…¶ä»–æ¶æ„éœ€è¦ä¿®æ”¹ `_register_router_hooks` æ–¹æ³•

### æŠ€æœ¯ç‰¹ç‚¹
1. **Forward Hooks**: è‡ªåŠ¨æ•è·æ¯å±‚çš„ router logits
2. **æ¢¯åº¦æµ**: ä¸ä½¿ç”¨ `detach()`ï¼Œä¿æŒæ¢¯åº¦å¯å›ä¼ 
3. **Batch-aware**: é€šè¿‡ `label_ids` å­—æ®µåŒºåˆ† safe/unsafe æ ·æœ¬
4. **è‡ªåŠ¨å¹³å‡**: è·¨åºåˆ—ä½ç½®å’Œå±‚æ•°å¹³å‡ï¼Œç¨³å®šè®­ç»ƒ

### è¾“å‡ºå’Œæ—¥å¿—
- æ¯ 100 æ­¥æ‰“å°ä¸€æ¬¡è¯¦ç»†æŸå¤±ï¼š
  ```
  Step 100: CE Loss: 2.3456, Router Loss: 0.0234, Total Loss: 2.3690
  ```
- è®­ç»ƒå…ƒæ•°æ®ä¿å­˜åœ¨ `training_metadata.json`ï¼ŒåŒ…å«æ‰€æœ‰ router consistency é…ç½®

## é¢„æœŸæ•ˆæœ

### ä¼˜åŠ¿
âœ… Router å­¦ä¹ åˆ° safe å’Œ unsafe æ ·æœ¬åº”æ¿€æ´»ç›¸ä¼¼ä¸“å®¶  
âœ… æœ‰åŠ©äº unsafe experts ä¸“é—¨å¤„ç† unsafe å†…å®¹ï¼Œè€Œä¸æ”¹å˜ router è¡Œä¸º  
âœ… ç†è®ºä¸Šå¯ä¿æŒ safe ä»»åŠ¡æ€§èƒ½ï¼ŒåŒæ—¶æå‡ unsafe ä»»åŠ¡æ‹’ç»èƒ½åŠ›

### æ½œåœ¨é£é™©
âš ï¸ å¦‚æœ safe å’Œ unsafe æœ¬è´¨ä¸Šéœ€è¦ä¸åŒä¸“å®¶ï¼Œçº¦æŸå¯èƒ½é™ä½è¡¨è¾¾èƒ½åŠ›  
âš ï¸ æƒé‡è®¾ç½®ä¸å½“å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼ˆKL æ•£åº¦å¯èƒ½å¾ˆå¤§ï¼‰  
âš ï¸ åªä¼˜åŒ– router ä¸€è‡´æ€§è€Œä¸ä¼˜åŒ– expertsï¼Œæ•ˆæœå¯èƒ½æœ‰é™

## è°ƒè¯•å’Œé—®é¢˜æ’æŸ¥

### æ£€æŸ¥æ˜¯å¦æ­£å¸¸å·¥ä½œ
1. è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š
   ```bash
   python3 test_router_consistency.py
   ```
   åº”è¯¥çœ‹åˆ°æ‰€æœ‰æµ‹è¯•é€šè¿‡ã€‚

2. æ£€æŸ¥è®­ç»ƒæ—¥å¿—ï¼š
   - å¯åŠ¨æ—¶åº”çœ‹åˆ° "Router Consistency Loss Configuration"
   - åº”çœ‹åˆ° "Registered N router hooks"
   - æ¯ 100 æ­¥åº”æœ‰è¯¦ç»†æŸå¤±æ‰“å°

3. æ£€æŸ¥æ¢¯åº¦ï¼š
   - Router loss åº”è¯¥ > 0
   - å¦‚æœå§‹ç»ˆä¸º 0ï¼Œå¯èƒ½ hooks æ²¡æœ‰æ­£ç¡®æ•è· logits

### å¸¸è§é—®é¢˜

**Q: Router Loss å§‹ç»ˆä¸º 0ï¼Ÿ**  
A: æ£€æŸ¥ `label_ids` æ˜¯å¦æ­£ç¡®ä¼ é€’ï¼Œç¡®ä¿ batch ä¸­åŒæ—¶æœ‰ safe å’Œ unsafe æ ·æœ¬ã€‚

**Q: è®­ç»ƒä¸ç¨³å®š/loss çˆ†ç‚¸ï¼Ÿ**  
A: é™ä½ `--router_consistency_weight`ï¼Œä» 0.01 å¼€å§‹å°è¯•ã€‚

**Q: æ”¯æŒå…¶ä»– MoE æ¶æ„ï¼Ÿ**  
A: ä¿®æ”¹ `ExpertMaskingTrainer._register_router_hooks` æ–¹æ³•ï¼Œæ·»åŠ å¯¹åº”æ¶æ„çš„ router ä½ç½®ã€‚

**Q: å¦‚ä½•åªè®¡ç®— unsafe expert æ‰€åœ¨å±‚çš„ lossï¼Ÿ**  
A: å½“å‰ `--router_consistency_layers unsafe_only` æœªå®ç°ï¼Œéœ€è¦é¢å¤–ä¼ å…¥ unsafe experts ä¿¡æ¯å¹¶åœ¨ `_compute_router_consistency_loss` ä¸­è¿‡æ»¤å±‚ã€‚

## å¼•ç”¨å’Œå‚è€ƒ

è¿™ä¸ªå®ç°åŸºäºä»¥ä¸‹ç†è®ºï¼š
- KL æ•£åº¦ä½œä¸ºåˆ†å¸ƒé—´è·ç¦»åº¦é‡
- MoE æ¨¡å‹çš„ router ä¸€è‡´æ€§çº¦æŸ
- Safe/Unsafe æ ·æœ¬çš„ä¸“å®¶é€‰æ‹©æ¨¡å¼

## æ›´æ–°æ—¥å¿—

- **2025-10-31**: åˆå§‹å®ç°
  - æ”¯æŒä¸‰ç§ KL æ•£åº¦ç±»å‹
  - è‡ªåŠ¨ forward hooks æ•è· router logits
  - å®Œæ•´çš„å‘½ä»¤è¡Œæ¥å£å’Œæ¶ˆèå®éªŒæ”¯æŒ

