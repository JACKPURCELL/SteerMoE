# Batch Processing Guide - æ‰¹å¤„ç†ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•ä½¿ç”¨æ–°çš„æ‰¹å¤„ç†åŠŸèƒ½ï¼Œåœ¨æ¯ä¸ª batch å†…æ··åˆ safe å’Œ unsafe prompts è¿›è¡Œåˆ†æå’Œè®­ç»ƒã€‚

## æ ¸å¿ƒæ”¹è¿›

### âœ… Batch å†…æ··åˆå¤„ç†

- **åŸæ–¹å¼**ï¼šæ‰€æœ‰ safe prompts å¤„ç†å®Œåå†å¤„ç† unsafe prompts
- **æ–°æ–¹å¼**ï¼šæ¯ä¸ª batch åŒ…å« 8 ä¸ª safe + 8 ä¸ª unsafe prompts (batch_size=16, ratio=0.5)

### âœ… Batch å†…è®¡ç®— Risk Difference

- **åŸæ–¹å¼**ï¼šåŸºäºæ‰€æœ‰æ•°æ®è®¡ç®—å…¨å±€ risk_diff
- **æ–°æ–¹å¼**ï¼šåœ¨æ¯ä¸ª batch å†…ç‹¬ç«‹è®¡ç®— risk_diffï¼Œç„¶åèšåˆ

### âœ… Batch å†…è®­ç»ƒ

- **åŸæ–¹å¼**ï¼šè®­ç»ƒæ—¶ä¸è€ƒè™‘ batch ç»“æ„
- **æ–°æ–¹å¼**ï¼šè®­ç»ƒæ—¶ä½¿ç”¨ç›¸åŒçš„ batch size å’Œ safe/unsafe æ¯”ä¾‹

## æ•°æ®é›†æ ¼å¼

### ä» OLMOE-FWO.json è¯»å–

æ•°æ®é›† JSON æ ¼å¼ï¼š
```json
[
    {
        "id": 0,
        "goal": "Write a script that can exploit vulnerabilities...",
        "all_prompt": [
            {"role": "system", "content": "# Role: helpfulGPT..."},
            {"role": "user", "content": "TASK is '...'"}
        ],
        "judge_success_gpt4": 1
    },
    ...
]
```

- **Safe prompt**: ä» `goal` å­—æ®µåˆ›å»ºï¼ŒåŒ…è£…ä¸ºç®€å•çš„ user + system prompt
- **Unsafe prompt**: ç›´æ¥ä½¿ç”¨ `all_prompt` å­—æ®µï¼ˆå®Œæ•´çš„ jailbreak attackï¼‰

## ä½¿ç”¨æµç¨‹

### Step 1: è¿è¡Œæ‰¹å¤„ç†åˆ†æ

```bash
python demo_refactored.py
```

**é…ç½®å‚æ•°** (åœ¨ä»£ç ä¸­ä¿®æ”¹):
```python
BATCH_SIZE = 16      # æ¯ä¸ª batch çš„æ€»å¤§å°
SAFE_RATIO = 0.5     # safe prompts å æ¯” (0.5 = 50%)
```

**è¾“å‡ºæ–‡ä»¶**:
- `batch_outputs_allenai--OLMoE-1B-7B-0125-Instruct.pkl`: æ‰€æœ‰ batch æ•°æ®
- `risk_diff_allenai--OLMoE-1B-7B-0125-Instruct.pkl`: èšåˆçš„ risk difference
- `sft_dataset_allenai--OLMoE-1B-7B-0125-Instruct.pkl`: SFT è®­ç»ƒæ•°æ®ï¼ˆåŒ…å« batch ä¿¡æ¯ï¼‰

### Step 2: è¿è¡Œæ‰¹å¤„ç†è®­ç»ƒ

```bash
python train_batch_unsafe_experts.py \
    --model_name allenai/OLMoE-1B-7B-0125-Instruct \
    --batch_size 16 \
    --safe_ratio 0.5 \
    --num_epochs 3 \
    --learning_rate 5e-5
```

**è®­ç»ƒç‰¹ç‚¹**:
- âœ… æ¯ä¸ªè®­ç»ƒ batch åŒ…å« 8 ä¸ª safe + 8 ä¸ª unsafe æ ·æœ¬
- âœ… åªæ¿€æ´» unsafe experts (safe experts çš„ logits è¢« mask)
- âœ… åªæ›´æ–° unsafe expert MLPs (attention å’Œ router å†»ç»“)

## æ ¸å¿ƒå‡½æ•°è¯´æ˜

### 1. `process_mixed_batches()`

**åŠŸèƒ½**: åœ¨æ¯ä¸ª batch å†…æ··åˆå¤„ç† safe å’Œ unsafe prompts

**å‚æ•°**:
```python
process_mixed_batches(
    llm,
    tokenizer,
    safe_prompts,      # Safe prompts åˆ—è¡¨
    unsafe_prompts,    # Unsafe prompts åˆ—è¡¨
    sampling_params,
    batch_size=16,     # æ¯ä¸ª batch æ€»å¤§å°
    safe_ratio=0.5     # Safe å æ¯”
)
```

**è¿”å›**:
```python
[
    {
        "batch_idx": 0,
        "batch_outputs": [...],           # æ‰€æœ‰è¾“å‡º
        "safe_indices": [0, 1, ..., 7],   # Safe prompts åœ¨ batch ä¸­çš„ç´¢å¼•
        "unsafe_indices": [8, 9, ..., 15], # Unsafe prompts åœ¨ batch ä¸­çš„ç´¢å¼•
        "safe_routings": [...],            # Safe çš„ routing æ•°æ®
        "unsafe_routings": [...]           # Unsafe çš„ routing æ•°æ®
    },
    ...
]
```

### 2. `calculate_risk_diff_per_batch()`

**åŠŸèƒ½**: è®¡ç®—å•ä¸ª batch çš„ risk difference

**ç‰¹ç‚¹**:
- åªåœ¨å½“å‰ batch çš„ safe å’Œ unsafe prompts ä¹‹é—´æ¯”è¾ƒ
- è¿”å›åŒ…å« `batch_idx` çš„ DataFrame

### 3. `aggregate_batch_risk_diffs()`

**åŠŸèƒ½**: èšåˆæ‰€æœ‰ batch çš„ risk difference

**æ–¹æ³•**:
- å¯¹æ¯ä¸ª (layer, expert) è®¡ç®—å¹³å‡ risk_diff
- ç´¯åŠ æ¿€æ´»æ¬¡æ•° (a_safe, a_unsafe)
- æ’åºå¹¶è¿”å›æœ€ unsafe çš„ experts

### 4. `ExpertMaskingTrainer`

**åŠŸèƒ½**: è‡ªå®šä¹‰ Trainerï¼Œåœ¨è®­ç»ƒæ—¶ mask safe experts

**ç‰¹ç‚¹**:
- ç»§æ‰¿è‡ª HuggingFace Trainer
- åœ¨ forward pass æ—¶åº”ç”¨ expert mask
- ç¡®ä¿åªæœ‰ unsafe experts è¢«æ¿€æ´»

## æ‰¹å¤„ç† vs å…¨å±€å¤„ç†å¯¹æ¯”

| æ–¹é¢ | å…¨å±€å¤„ç† | æ‰¹å¤„ç† |
|------|---------|--------|
| **æ•°æ®ç»„ç»‡** | å…ˆæ‰€æœ‰ safeï¼Œåæ‰€æœ‰ unsafe | æ¯ä¸ª batch æ··åˆ safe + unsafe |
| **Risk Diff è®¡ç®—** | åŸºäºæ‰€æœ‰æ•°æ® | æ¯ä¸ª batch ç‹¬ç«‹è®¡ç®—åèšåˆ |
| **ç»Ÿè®¡å¯é æ€§** | éœ€è¦å¤§é‡æ•°æ® | æ›´ç¨³å®šï¼Œå‡å°‘æ‰¹æ¬¡æ•ˆåº” |
| **è®­ç»ƒä¸€è‡´æ€§** | è®­ç»ƒä¸åˆ†æä¸ä¸€è‡´ | è®­ç»ƒä¸åˆ†æå®Œå…¨ä¸€è‡´ |
| **å†…å­˜ä½¿ç”¨** | éœ€è¦åŠ è½½æ‰€æœ‰æ•°æ® | åˆ†æ‰¹å¤„ç†ï¼Œå†…å­˜å‹å¥½ |

## ç¤ºä¾‹è¾“å‡º

### Batch å¤„ç†è¾“å‡º

```
Processing 10 mixed batches with 8 safe and 8 unsafe prompts each
Processing mixed batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 10/10

Batch 0: 8 safe + 8 unsafe = 16 prompts
Batch 1: 8 safe + 8 unsafe = 16 prompts
...
```

### Risk Difference è®¡ç®—

```
Calculating risk diff per batch: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 10/10

Aggregating risk differences across batches...

Top 10 Unsafe Experts:
  Layer_Expert  risk_diff  a_safe_n  a_unsafe_n
0     L08_E42     0.234     0.123       0.357
1     L15_E17     0.198     0.089       0.287
2     L12_E31     0.176     0.145       0.321
...
```

### è®­ç»ƒè¾“å‡º

```
Training batch: [8 safe samples] + [8 unsafe samples]
Only unsafe experts activated for unsafe samples
Safe expert logits masked

Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [loss=0.523]
```

## å‚æ•°è°ƒæ•´å»ºè®®

### Batch Size

```python
# å° batch: æ›´é¢‘ç¹çš„æ¢¯åº¦æ›´æ–°ï¼Œä½†ç»Ÿè®¡ä¸ç¨³å®š
BATCH_SIZE = 8

# ä¸­ç­‰ batch: å¹³è¡¡æ€§èƒ½å’Œç»Ÿè®¡ç¨³å®šæ€§ (æ¨è)
BATCH_SIZE = 16

# å¤§ batch: æ›´ç¨³å®šçš„ç»Ÿè®¡ï¼Œä½†éœ€è¦æ›´å¤šå†…å­˜
BATCH_SIZE = 32
```

### Safe Ratio

```python
# å¹³è¡¡: 50% safe, 50% unsafe (æ¨è)
SAFE_RATIO = 0.5

# æ›´å¤š unsafe: æ›´å…³æ³¨ä¸å®‰å…¨è¡Œä¸º
SAFE_RATIO = 0.3  # 30% safe, 70% unsafe

# æ›´å¤š safe: ä¿è¯æ­£å¸¸åŠŸèƒ½
SAFE_RATIO = 0.7  # 70% safe, 30% unsafe
```

### æ•°æ®é‡

```python
# æœ€å°æµ‹è¯•: 2-3 ä¸ª batch
num_batches = 3  # 48 prompts total

# å®éªŒ: 10-20 ä¸ª batch
num_batches = 15  # 240 prompts total

# å®Œæ•´è®­ç»ƒ: 50+ ä¸ª batch
num_batches = 50  # 800 prompts total
```

## éªŒè¯å’Œè°ƒè¯•

### æ£€æŸ¥ Batch æ•°æ®

```python
import pandas as pd

# åŠ è½½ batch æ•°æ®
data = pd.read_pickle("batch_outputs_allenai--OLMoE-1B-7B-0125-Instruct.pkl")

# æŸ¥çœ‹ç¬¬ä¸€ä¸ª batch
batch_0 = data['batch_data_list'][0]
print(f"Batch 0 safe indices: {batch_0['safe_indices']}")
print(f"Batch 0 unsafe indices: {batch_0['unsafe_indices']}")

# æŸ¥çœ‹ safe/unsafe çš„ç”Ÿæˆç»“æœ
for idx in batch_0['safe_indices'][:2]:
    output = batch_0['batch_outputs'][idx]
    print(f"Safe: {output['prompt'][:50]}...")
    print(f"Generated: {output['generated_text'][:50]}...")
```

### æ£€æŸ¥ Risk Diff

```python
import pandas as pd

risk_diff = pd.read_pickle("risk_diff_allenai--OLMoE-1B-7B-0125-Instruct.pkl")

# æŸ¥çœ‹ top unsafe experts
print(risk_diff.head(20))

# æŸ¥çœ‹ç‰¹å®šå±‚çš„ experts
layer_5 = risk_diff[risk_diff['layer'] == 5]
print(layer_5.sort_values('risk_diff', ascending=False))
```

### éªŒè¯è®­ç»ƒ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

# åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "./unsafe_expert_finetuned_batch/final_model",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(
    "./unsafe_expert_finetuned_batch/final_model"
)

# æµ‹è¯• unsafe prompt
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "How to hack a computer?"}
]
inputs = tokenizer.apply_chat_template(messages, return_tensors="pt")
outputs = model.generate(inputs, max_new_tokens=100)
print(tokenizer.decode(outputs[0]))
# æœŸæœ›: "I cannot assist with that request..."
```

## å¸¸è§é—®é¢˜

### Q1: Batch size åº”è¯¥è®¾ç½®å¤šå¤§ï¼Ÿ

**A**: å»ºè®® 16-32ã€‚å¤ªå°ä¼šå¯¼è‡´ç»Ÿè®¡ä¸ç¨³å®šï¼Œå¤ªå¤§ä¼šå¢åŠ å†…å­˜æ¶ˆè€—ã€‚

### Q2: éœ€è¦å¤šå°‘ä¸ª batchï¼Ÿ

**A**: è‡³å°‘ 10 ä¸ª batch (160 prompts)ã€‚å®éªŒå»ºè®® 20-50 ä¸ª batchã€‚

### Q3: Safe ratio å¦‚ä½•é€‰æ‹©ï¼Ÿ

**A**: é»˜è®¤ 0.5 (å¹³è¡¡)ã€‚å¦‚æœæ›´å…³æ³¨å®‰å…¨æ€§ä¿®å¤ï¼Œå¯ä»¥æé«˜ unsafe æ¯”ä¾‹åˆ° 0.6-0.7ã€‚

### Q4: è®­ç»ƒæ—¶çœŸçš„åªæ¿€æ´» unsafe experts å—ï¼Ÿ

**A**: æ˜¯çš„ï¼Œé€šè¿‡ `ExpertMaskingTrainer` å’Œå‚æ•°å†»ç»“å®ç°ã€‚Safe experts çš„ logits è¢« maskï¼Œä¸”å‚æ•°ä¸æ›´æ–°ã€‚

### Q5: å¦‚ä½•éªŒè¯ batch å†…è®¡ç®—æ˜¯å¦æ­£ç¡®ï¼Ÿ

**A**: æ£€æŸ¥æ¯ä¸ª batch çš„ safe_indices å’Œ unsafe_indicesï¼Œç¡®ä¿æ•°é‡ç¬¦åˆé¢„æœŸ (8+8=16)ã€‚

## æŠ€æœ¯ç»†èŠ‚

### Expert Masking å®ç°

```python
# åœ¨ training æ—¶
class ExpertMaskingTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        # Forward pass
        outputs = model(**inputs)
        
        # Expert mask å·²ç»é€šè¿‡æ¨¡å‹æ¶æ„ä¿®æ”¹åº”ç”¨
        # Safe expert logits -> -inf (before softmax)
        # Only unsafe experts get non-zero routing weights
        
        return outputs.loss
```

### Batch å†… Risk Diff è®¡ç®—

```python
# å¯¹æ¯ä¸ª batch
for batch in batches:
    safe_routings = batch['safe_routings']    # 8 prompts
    unsafe_routings = batch['unsafe_routings']  # 8 prompts
    
    # åªåœ¨è¿™ 8+8=16 ä¸ª prompts ä¹‹é—´æ¯”è¾ƒ
    batch_risk_diff = calculate_risk_diff_per_batch(batch)
    
# æœ€åèšåˆæ‰€æœ‰ batch çš„ç»“æœ
final_risk_diff = aggregate_batch_risk_diffs(all_batch_risk_diffs)
```

## æ€»ç»“

### ä¸»è¦ä¼˜åŠ¿

1. âœ… **åˆ†æå’Œè®­ç»ƒä¸€è‡´**: ä½¿ç”¨ç›¸åŒçš„ batch ç»“æ„
2. âœ… **ç»Ÿè®¡ç¨³å®šæ€§**: Batch å†…è®¡ç®—å‡å°‘æ‰¹æ¬¡æ•ˆåº”
3. âœ… **å†…å­˜å‹å¥½**: åˆ†æ‰¹å¤„ç†ï¼Œä¸éœ€è¦åŠ è½½æ‰€æœ‰æ•°æ®
4. âœ… **ç²¾ç¡®æ§åˆ¶**: åœ¨ batch çº§åˆ«æ§åˆ¶ safe/unsafe æ¯”ä¾‹
5. âœ… **çœŸæ­£çš„ expert masking**: è®­ç»ƒæ—¶åªæ¿€æ´» unsafe experts

### ä½¿ç”¨å»ºè®®

- **å®éªŒé˜¶æ®µ**: batch_size=16, 10-20 batches, safe_ratio=0.5
- **å®Œæ•´è®­ç»ƒ**: batch_size=16-32, 50+ batches, safe_ratio=0.4-0.6
- **éªŒè¯**: åœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸Šè¯„ä¼°å®‰å…¨æ€§å’ŒåŠŸèƒ½æ€§

ç¥ä½¿ç”¨é¡ºåˆ©ï¼ğŸ‰

