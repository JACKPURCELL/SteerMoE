# Per-Batch Unsafe Experts - æ¯ä¸ª Batch æœ‰è‡ªå·±çš„ Unsafe Experts

## æ ¸å¿ƒæ”¹è¿›

**ç°åœ¨æ¯ä¸ª batch éƒ½æœ‰è‡ªå·±ç‹¬ç«‹è¯†åˆ«çš„ unsafe expertsï¼**

### ä¹‹å‰çš„å®ç°

```python
# æ‰€æœ‰ batch å…±äº«åŒä¸€ä¸ª unsafe experts åˆ—è¡¨
all_batches = [batch_0, batch_1, batch_2, ...]
â†“ è®¡ç®—æ¯ä¸ª batch çš„ risk_diff
â†“ èšåˆæ‰€æœ‰ batch
â†“ è¯†åˆ«ä¸€ä¸ªå…¨å±€çš„ unsafe_experts åˆ—è¡¨
global_unsafe_experts = [(L0, E5), (L2, E8), ...]  # æ‰€æœ‰ batch å…±ç”¨
```

### ç°åœ¨çš„å®ç°

```python
# æ¯ä¸ª batch æœ‰è‡ªå·±çš„ unsafe experts
batch_0 â†’ risk_diff_0 â†’ unsafe_experts_0 = [(L0, E5), (L1, E12), ...]
batch_1 â†’ risk_diff_1 â†’ unsafe_experts_1 = [(L0, E8), (L2, E3), ...]
batch_2 â†’ risk_diff_2 â†’ unsafe_experts_2 = [(L1, E15), (L3, E7), ...]
...

# æ¯ä¸ª batch æœ‰è‡ªå·±çš„ expert mask
batch_0 â†’ expert_mask_0
batch_1 â†’ expert_mask_1
batch_2 â†’ expert_mask_2
```

## ä¸ºä»€ä¹ˆéœ€è¦ Per-Batch Expertsï¼Ÿ

### 1. ä¸åŒçš„ unsafe prompts æ¿€æ´»ä¸åŒçš„ experts

```
Batch 0 (hacking prompts):
  â†’ å¯èƒ½æ›´å¤šæ¿€æ´» L5_E12, L8_E7 (æŠ€æœ¯ç›¸å…³ experts)

Batch 1 (violence prompts):
  â†’ å¯èƒ½æ›´å¤šæ¿€æ´» L3_E9, L10_E15 (æš´åŠ›ç›¸å…³ experts)

Batch 2 (illegal content):
  â†’ å¯èƒ½æ›´å¤šæ¿€æ´» L2_E4, L7_E11 (æ³•å¾‹ç›¸å…³ experts)
```

### 2. æ›´ç²¾ç»†çš„æ§åˆ¶

- å¯ä»¥é’ˆå¯¹æ€§åœ°ä¿®å¤æ¯ä¸ª batch å¯¹åº”çš„ experts
- é¿å…è¿‡åº¦ä¿®å¤ä¸ç›¸å…³çš„ experts
- ä¿æŒæ¨¡å‹åœ¨å…¶ä»–é¢†åŸŸçš„èƒ½åŠ›

### 3. æ›´å¥½çš„å¯è§£é‡Šæ€§

- å¯ä»¥åˆ†æå“ªäº› experts å¯¹ç‰¹å®šç±»å‹çš„ unsafe å†…å®¹è´Ÿè´£
- å¯ä»¥è¿½è¸ªæ¯ä¸ª batch çš„è®­ç»ƒæ•ˆæœ
- ä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–

## å®ç°ç»†èŠ‚

### 1. åˆ†æé˜¶æ®µï¼ˆdemo_refactored.pyï¼‰

```python
# ä¸ºæ¯ä¸ª batch ç‹¬ç«‹è®¡ç®—å’Œè¯†åˆ«
batch_unsafe_experts = []
batch_expert_masks = []

for batch_data in batch_data_list:
    # 1. è®¡ç®—è¿™ä¸ª batch çš„ risk_diff
    batch_risk_diff = calculate_risk_diff_per_batch(batch_data, num_experts_per_tok)
    
    # 2. è¯†åˆ«è¿™ä¸ª batch çš„ unsafe experts
    batch_unsafe = identify_unsafe_experts(batch_risk_diff, threshold=0.05, top_k=50)
    batch_unsafe_experts.append(batch_unsafe)
    
    # 3. åˆ›å»ºè¿™ä¸ª batch çš„ expert mask
    batch_mask = create_expert_mask(num_layers, n_experts, batch_unsafe)
    batch_expert_masks.append(batch_mask)

# ä¿å­˜
sft_data = {
    "batch_unsafe_experts": batch_unsafe_experts,  # List[List[(layer, expert)]]
    "batch_expert_masks": batch_expert_masks,      # List[np.ndarray]
}
```

### 2. è®­ç»ƒé˜¶æ®µï¼ˆtrain_batch_unsafe_experts.pyï¼‰

#### å‚æ•°å†»ç»“ï¼šå–å¹¶é›†

```python
def freeze_model_except_unsafe_experts(model, batch_unsafe_experts):
    # å–æ‰€æœ‰ batch çš„ unsafe experts çš„å¹¶é›†
    all_unsafe_experts = set()
    for batch_experts in batch_unsafe_experts:
        all_unsafe_experts.update(batch_experts)
    
    # è§£å†»æ‰€æœ‰å‡ºç°è¿‡çš„ unsafe experts
    # è¿™æ ·æ¯ä¸ª batch éœ€è¦çš„ experts éƒ½æ˜¯å¯è®­ç»ƒçš„
    for layer, expert in all_unsafe_experts:
        unfreeze_expert(model, layer, expert)
```

**åŸå› **ï¼š
- Batch 0 å¯èƒ½éœ€è¦ Expert A å’Œ B
- Batch 1 å¯èƒ½éœ€è¦ Expert B å’Œ C
- éœ€è¦è§£å†» A, B, Cï¼ˆå¹¶é›†ï¼‰ï¼Œè¿™æ ·ä¸¤ä¸ª batch éƒ½èƒ½è®­ç»ƒ

#### åŠ¨æ€ Expert Maskingï¼šæ ¹æ® batch_idx

```python
class ExpertMaskingTrainer(Trainer):
    def __init__(self, batch_expert_masks, ...):
        # ä¿å­˜æ‰€æœ‰ batch çš„ mask
        self.batch_expert_masks = batch_expert_masks  # List of masks
    
    def compute_loss(self, model, inputs, return_outputs=False):
        # è·å–å½“å‰ batch çš„ batch_idx
        batch_idx = inputs['batch_idx'][0].item()
        
        # ä½¿ç”¨å¯¹åº”çš„ expert mask
        current_mask = self.batch_expert_masks[batch_idx]
        
        # åº”ç”¨ maskï¼šåªæ¿€æ´»è¿™ä¸ª batch çš„ unsafe experts
        # Safe experts çš„ logits è¢« mask
        ...
```

**å…³é”®**ï¼šè®­ç»ƒæ—¶æ ¹æ® `batch_idx` åŠ¨æ€é€‰æ‹© maskï¼

## æ•°æ®æµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch 0: [8 safe + 8 unsafe (hacking)]            â”‚
â”‚   â†“ Calculate risk_diff for this batch            â”‚
â”‚   â†“ Identify unsafe_experts_0: [(L5,E12), ...]    â”‚
â”‚   â†“ Create expert_mask_0                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch 1: [8 safe + 8 unsafe (violence)]           â”‚
â”‚   â†“ Calculate risk_diff for this batch            â”‚
â”‚   â†“ Identify unsafe_experts_1: [(L3,E9), ...]     â”‚
â”‚   â†“ Create expert_mask_1                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“
    Save all batch-specific data
         â†“
         
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Training:                                           â”‚
â”‚                                                     â”‚
â”‚ 1. Unfreeze union of all unsafe experts           â”‚
â”‚    (so all batches can train their experts)        â”‚
â”‚                                                     â”‚
â”‚ 2. For each training batch:                        â”‚
â”‚    - Read batch_idx from data                      â”‚
â”‚    - Use corresponding expert_mask                 â”‚
â”‚    - Only activate that batch's unsafe experts     â”‚
â”‚    - Update only those experts' parameters         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ç¤ºä¾‹è¾“å‡º

### åˆ†æé˜¶æ®µ

```
Step 3: Calculate Risk Difference Per Batch
==========================================
Calculating risk diff per batch: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 10/10

Step 4: Unsafe Experts Summary
==========================================
Number of batches: 10

Per-batch unsafe experts count:
  Batch 0: 47 unsafe experts
  Batch 1: 52 unsafe experts
  Batch 2: 43 unsafe experts
  Batch 3: 50 unsafe experts
  Batch 4: 45 unsafe experts

Global top 10 unsafe experts (aggregated):
  Layer_Expert  risk_diff  a_safe_n  a_unsafe_n
0     L08_E42     0.234     0.123       0.357
1     L15_E17     0.198     0.089       0.287
2     L12_E31     0.176     0.145       0.321
...

Batch 0 top 5 unsafe experts:
   layer  expert  risk_diff
0      8      42      0.245
1     15      17      0.212
2     12      31      0.189
3      5      23      0.178
4     18       9      0.165
```

### è®­ç»ƒé˜¶æ®µ

```
Loading prepared batch data...
==========================================
Loaded SFT data: 160 examples
Number of batches: 10

Per-batch unsafe experts:
  Batch 0: 47 unsafe experts
  Batch 1: 52 unsafe experts
  Batch 2: 43 unsafe experts

Freezing model parameters...
==========================================
Unfreezing union of unsafe experts from all batches:
  Total unique unsafe experts across all batches: 85

Parameter freezing complete:
  Unfrozen 85 unsafe expert MLPs (union across all batches)
  Trainable: 12,345,678 / 1,234,567,890 (1.00%)

Starting training...
==========================================
Batch size: 16
Safe ratio: 0.5 (8 safe + 8 unsafe per batch)
Number of batches: 10
Each batch has its own set of unsafe experts!

Per-batch unsafe expert counts:
  Min: 43, Max: 52, Mean: 47.8

Total unique unsafe experts (union): 85
These experts' MLPs are unfrozen for training
But only batch-specific experts are activated per batch!
==========================================

Training Batch 0: Uses expert_mask_0 (47 experts)
Training Batch 1: Uses expert_mask_1 (52 experts)
Training Batch 2: Uses expert_mask_2 (43 experts)
...
```

## ä¼˜åŠ¿

### 1. ç²¾ç¡®æ€§

```python
# ä¹‹å‰ï¼šæ‰€æœ‰ batch ç”¨åŒä¸€ä¸ª mask
Batch 0 (hacking): uses global_mask (100 experts)
Batch 1 (violence): uses global_mask (100 experts)  # å¯èƒ½åŒ…å«ä¸ç›¸å…³çš„ experts

# ç°åœ¨ï¼šæ¯ä¸ª batch ç”¨è‡ªå·±çš„ mask
Batch 0 (hacking): uses mask_0 (47 hacking-related experts)  âœ“
Batch 1 (violence): uses mask_1 (52 violence-related experts)  âœ“
```

### 2. æ•ˆç‡

- æ¯ä¸ª batch åªè®­ç»ƒç›¸å…³çš„ experts
- é¿å…æµªè´¹è®¡ç®—åœ¨ä¸ç›¸å…³çš„ experts ä¸Š
- è®­ç»ƒæ›´èšç„¦

### 3. çµæ´»æ€§

```python
# å¯ä»¥å•ç‹¬åˆ†ææ¯ä¸ª batch
batch_0_performance = evaluate(model, batch_0_data)
batch_1_performance = evaluate(model, batch_1_data)

# å¯ä»¥é’ˆå¯¹æ€§è°ƒæ•´
if batch_0_performance < threshold:
    # å¢åŠ  batch 0 çš„è®­ç»ƒæƒé‡
    # æˆ–è€…é‡æ–°è¯†åˆ« batch 0 çš„ unsafe experts
```

### 4. å¯è§£é‡Šæ€§

```python
# å¯ä»¥å›ç­”é—®é¢˜ï¼š
"å“ªäº› experts å¯¹ hacking ç±»å†…å®¹è´Ÿè´£ï¼Ÿ"
â†’ æŸ¥çœ‹ batch_0 (hacking) çš„ unsafe_experts_0

"å“ªäº› experts å¯¹ violence ç±»å†…å®¹è´Ÿè´£ï¼Ÿ"
â†’ æŸ¥çœ‹ batch_1 (violence) çš„ unsafe_experts_1

"æœ‰å“ªäº› experts å¯¹å¤šç§ unsafe å†…å®¹è´Ÿè´£ï¼Ÿ"
â†’ æ‰¾å‡ºç°åœ¨å¤šä¸ª batch çš„ unsafe experts
```

## æ•°æ®ç»“æ„

### ä¿å­˜çš„æ•°æ®

```python
sft_data = {
    # Per-batch ä¿¡æ¯
    "batch_unsafe_experts": [
        [(0, 5), (1, 12), ...],  # Batch 0 çš„ unsafe experts
        [(0, 8), (2, 3), ...],   # Batch 1 çš„ unsafe experts
        ...
    ],
    
    "batch_expert_masks": [
        np.array([[0, 0, 1, ...], ...]),  # Batch 0 çš„ mask
        np.array([[0, 1, 0, ...], ...]),  # Batch 1 çš„ mask
        ...
    ],
    
    # å…¨å±€ä¿¡æ¯ï¼ˆå‚è€ƒï¼‰
    "aggregated_risk_diff": pd.DataFrame(...),  # èšåˆçš„ risk_diff
    "global_unsafe_experts": [...],              # å…¨å±€è¯†åˆ«çš„ unsafe experts
}
```

### æ£€æŸ¥æ•°æ®

```python
import pandas as pd

# åŠ è½½æ•°æ®
data = pd.read_pickle("sft_dataset_*.pkl")

# æŸ¥çœ‹æ¯ä¸ª batch çš„ unsafe experts
for i, experts in enumerate(data['batch_unsafe_experts'][:3]):
    print(f"Batch {i}: {len(experts)} unsafe experts")
    print(f"  Sample: {list(experts)[:5]}")

# æŸ¥çœ‹é‡å 
batch_0_set = set(data['batch_unsafe_experts'][0])
batch_1_set = set(data['batch_unsafe_experts'][1])
overlap = batch_0_set & batch_1_set
print(f"Overlap between batch 0 and 1: {len(overlap)} experts")
```

## è®­ç»ƒç›‘æ§

å¯ä»¥æ·»åŠ ç›‘æ§æ¥éªŒè¯æ¯ä¸ª batch ä½¿ç”¨äº†æ­£ç¡®çš„ maskï¼š

```python
class BatchMonitoringTrainer(ExpertMaskingTrainer):
    def training_step(self, model, inputs):
        batch_idx = inputs['batch_idx'][0].item()
        
        # éªŒè¯ä½¿ç”¨äº†æ­£ç¡®çš„ mask
        expected_mask = self.batch_expert_masks[batch_idx]
        assert torch.equal(self.current_expert_mask, expected_mask.to(self.args.device))
        
        print(f"Training batch_idx={batch_idx}, "
              f"using {expected_mask.sum().item():.0f} unsafe experts")
        
        return super().training_step(model, inputs)
```

## æ€»ç»“

### å…³é”®ç‚¹

1. âœ… **æ¯ä¸ª batch ç‹¬ç«‹è¯†åˆ« unsafe experts**
2. âœ… **ä¿å­˜æ¯ä¸ª batch çš„ expert mask**
3. âœ… **è®­ç»ƒæ—¶è§£å†»æ‰€æœ‰ batch çš„ unsafe experts çš„å¹¶é›†**
4. âœ… **æ ¹æ® batch_idx åŠ¨æ€ä½¿ç”¨å¯¹åº”çš„ mask**
5. âœ… **æ›´ç²¾ç¡®ã€æ›´é«˜æ•ˆã€æ›´å¯è§£é‡Š**

### ä½¿ç”¨å»ºè®®

- **åˆ†æå¤šä¸ª batch çš„å·®å¼‚**ï¼šäº†è§£ä¸åŒç±»å‹ unsafe å†…å®¹çš„ expert pattern
- **ç›‘æ§è®­ç»ƒè¿‡ç¨‹**ï¼šç¡®ä¿æ¯ä¸ª batch ä½¿ç”¨äº†æ­£ç¡®çš„ mask
- **è¯„ä¼°åˆ† batch æ•ˆæœ**ï¼šå•ç‹¬è¯„ä¼°æ¯ç±» unsafe å†…å®¹çš„ä¿®å¤æ•ˆæœ

è¿™ä¸ªè®¾è®¡å……åˆ†åˆ©ç”¨äº† batch å†…åˆ†æçš„ä¼˜åŠ¿ï¼Œå®ç°äº†çœŸæ­£çš„ç²¾ç»†åŒ–æ§åˆ¶ï¼ğŸ¯

